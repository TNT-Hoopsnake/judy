judge: gpt-4-1106-preview
judge_api_key: null
judge_temperature: 0.6
use_proxy: false
proxies:
  http: http://sample-proxy
  https: http://sample-proxy
random_seed: 12345
num_evals: 2
max_tokens: 1000
context_char_limit: 1000
temperature: 1.1
scenarios: ["inst-flask"]
models:
  - id: flan-t5-small-take-3
    api_type: tgi
    api_base: http://localhost:8080
    temperature: 1.5
    family: generic
